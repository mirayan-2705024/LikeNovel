"""
å®Œæ•´åˆ†ææ¼”ç¤ºè„šæœ¬ - å±•ç¤ºMilestone 2çš„æ‰€æœ‰åŠŸèƒ½
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.config import Config
from backend.database.neo4j_client import Neo4jClient
from backend.parsers.txt_parser import TxtParser
from backend.extractors.entity_extractor import EntityExtractor
from backend.analyzers.character_analyzer import CharacterAnalyzer
from backend.analyzers.timeline_analyzer import TimelineAnalyzer
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def demo_full_analysis(file_path: str):
    """
    å®Œæ•´åˆ†ææ¼”ç¤º

    Args:
        file_path: å°è¯´æ–‡ä»¶è·¯å¾„
    """
    print("\n" + "=" * 70)
    print("ğŸ­ å°è¯´è„‰ç»œåˆ†æç³»ç»Ÿ - å®Œæ•´åˆ†ææ¼”ç¤º (Milestone 2)")
    print("=" * 70)

    # 1. è§£æå°è¯´
    print("\nğŸ“š æ­¥éª¤ 1: è§£æå°è¯´æ–‡ä»¶...")
    parser = TxtParser()
    novel_data = parser.parse(file_path)
    print(f"  âœ“ è§£æå®Œæˆ: {novel_data['total_chapters']}ç« , {novel_data['total_words']}å­—")

    # 2. æå–å®ä½“
    print("\nğŸ‘¥ æ­¥éª¤ 2: æå–äººç‰©å’Œåœ°ç‚¹...")
    extractor = EntityExtractor(min_mentions=2)
    entities = extractor.extract_entities_from_novel(novel_data)
    print(f"  âœ“ æå–å®Œæˆ: {len(entities['characters'])}ä¸ªäººç‰©, {len(entities['locations'])}ä¸ªåœ°ç‚¹")

    # 3. åˆ†æäººç‰©å…³ç³»
    print("\nğŸ”— æ­¥éª¤ 3: åˆ†æäººç‰©å…³ç³»...")
    char_analyzer = CharacterAnalyzer()
    char_analysis = char_analyzer.analyze(
        novel_data['chapters'],
        entities['characters']
    )
    print(f"  âœ“ åˆ†æå®Œæˆ: {len(char_analysis['relations'])}ä¸ªå…³ç³»")
    print(f"  - ä¸»è¦äººç‰©: {len(char_analysis['main_characters'])}ä¸ª")
    print(f"  - æ¬¡è¦äººç‰©: {len(char_analysis['supporting_characters'])}ä¸ª")
    print(f"  - ç½‘ç»œå¯†åº¦: {char_analysis['network']['density']:.3f}")

    # 4. åˆ†ææ—¶é—´çº¿
    print("\nâ±ï¸  æ­¥éª¤ 4: åˆ†ææ—¶é—´çº¿å’Œäº‹ä»¶...")
    timeline_analyzer = TimelineAnalyzer()
    timeline_analysis = timeline_analyzer.analyze(
        novel_data['chapters'],
        char_analysis['characters'],
        char_analysis['relations']
    )
    print(f"  âœ“ åˆ†æå®Œæˆ: {timeline_analysis['statistics']['total_events']}ä¸ªäº‹ä»¶")
    print(f"  - å¤§äº‹ä»¶: {timeline_analysis['statistics']['major_events']}ä¸ª")
    print(f"  - å°äº‹ä»¶: {timeline_analysis['statistics']['minor_events']}ä¸ª")
    print(f"  - ä¸»çº¿äº‹ä»¶: {timeline_analysis['statistics']['main_plot_events']}ä¸ª")
    print(f"  - å› æœå…³ç³»: {timeline_analysis['statistics']['causal_relations']}ä¸ª")

    # 5. æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ“Š è¯¦ç»†åˆ†æç»“æœ")
    print("=" * 70)

    # æ˜¾ç¤ºä¸»è¦äººç‰©
    print("\nğŸ‘‘ ä¸»è¦äººç‰©:")
    for char in char_analysis['main_characters'][:5]:
        print(f"  {char['name']}")
        print(f"    - é‡è¦æ€§: {char['final_importance']:.3f}")
        print(f"    - æåŠæ¬¡æ•°: {char['mention_count']}")
        print(f"    - å…³ç³»æ•°: {char['degree_centrality']}")
        print(f"    - é¦–æ¬¡å‡ºç°: ç¬¬{char['first_appearance']}ç« ")

    # æ˜¾ç¤ºä¸»è¦å…³ç³»
    print("\nğŸ¤ ä¸»è¦å…³ç³»:")
    for rel in char_analysis['relations'][:10]:
        print(f"  {rel['from']} â†â†’ {rel['to']}")
        print(f"    - ç±»å‹: {rel['relationship_type']}")
        print(f"    - å¼ºåº¦: {rel['strength']:.2f}")
        print(f"    - é¦–æ¬¡ç›¸é‡: ç¬¬{rel['first_met_chapter']}ç« ")

    # æ˜¾ç¤ºä¸»çº¿äº‹ä»¶
    print("\nğŸ“– ä¸»çº¿äº‹ä»¶:")
    for event in timeline_analysis['main_plot_events'][:10]:
        print(f"  ç¬¬{event['chapter']}ç« : {event['description'][:60]}...")
        print(f"    - é‡è¦æ€§: {event['importance_score']:.2f}")
        print(f"    - è´¡çŒ®åº¦: {event['contribution_score']:.2f}")
        print(f"    - ç±»å‹: {event['contribution_type']}")
        print(f"    - å‚ä¸è€…: {', '.join(event['participants'])}")

    # 6. ä¿å­˜åˆ°æ•°æ®åº“
    response = input("\nğŸ’¾ æ˜¯å¦è¦å°†åˆ†æç»“æœä¿å­˜åˆ°Neo4jæ•°æ®åº“? (yes/no): ")
    if response.lower() == 'yes':
        save_to_neo4j(novel_data, char_analysis, timeline_analysis)

    return {
        "novel_data": novel_data,
        "entities": entities,
        "char_analysis": char_analysis,
        "timeline_analysis": timeline_analysis
    }


def save_to_neo4j(novel_data, char_analysis, timeline_analysis):
    """
    ä¿å­˜åˆ†æç»“æœåˆ°Neo4j

    Args:
        novel_data: å°è¯´æ•°æ®
        char_analysis: äººç‰©åˆ†æç»“æœ
        timeline_analysis: æ—¶é—´çº¿åˆ†æç»“æœ
    """
    print("\nğŸ’¾ ä¿å­˜åˆ°Neo4jæ•°æ®åº“...")

    try:
        client = Neo4jClient(
            uri=Config.NEO4J_URI,
            user=Config.NEO4J_USER,
            password=Config.NEO4J_PASSWORD
        )

        # ä¿å­˜ç« èŠ‚
        print("  - ä¿å­˜ç« èŠ‚...")
        for chapter in novel_data['chapters']:
            client.create_node("Chapter", {
                "number": chapter["number"],
                "title": chapter["title"],
                "word_count": chapter["word_count"]
            })

        # ä¿å­˜äººç‰©
        print("  - ä¿å­˜äººç‰©...")
        for char in char_analysis['characters']:
            client.create_node("Character", {
                "id": char["id"],
                "name": char["name"],
                "mention_count": char["mention_count"],
                "first_appearance": char["first_appearance"],
                "importance": char.get("final_importance", char.get("importance", 0)),
                "degree_centrality": char.get("degree_centrality", 0)
            })

        # ä¿å­˜å…³ç³»
        print("  - ä¿å­˜äººç‰©å…³ç³»...")
        for rel in char_analysis['relations']:
            client.create_relationship(
                ("Character", "name", rel["from"]),
                ("Character", "name", rel["to"]),
                "KNOWS",
                {
                    "relationship_type": rel["relationship_type"],
                    "strength": rel["strength"],
                    "first_met_chapter": rel["first_met_chapter"]
                }
            )

        # ä¿å­˜äº‹ä»¶
        print("  - ä¿å­˜äº‹ä»¶...")
        for event in timeline_analysis['events'][:50]:  # é™åˆ¶æ•°é‡
            client.create_node("Event", {
                "id": event["id"],
                "description": event["description"],
                "chapter": event["chapter"],
                "sequence": event["sequence"],
                "event_type": event["event_type"],
                "importance_score": event["importance_score"],
                "contribution_score": event.get("contribution_score", 0)
            })

            # è¿æ¥äººç‰©å’Œäº‹ä»¶
            for participant in event["participants"]:
                try:
                    client.create_relationship(
                        ("Character", "name", participant),
                        ("Event", "id", event["id"]),
                        "PARTICIPATES_IN",
                        {"role": "å‚ä¸è€…"}
                    )
                except:
                    pass  # å¿½ç•¥é”™è¯¯

        # ä¿å­˜äº‹ä»¶é¡ºåºå…³ç³»
        print("  - ä¿å­˜äº‹ä»¶æ—¶é—´çº¿...")
        timeline = timeline_analysis['timeline']
        for i in range(len(timeline) - 1):
            try:
                client.create_relationship(
                    ("Event", "id", timeline[i]["id"]),
                    ("Event", "id", timeline[i+1]["id"]),
                    "NEXT",
                    {"time_gap": timeline[i+1].get("time_gap_from_prev", "æœªçŸ¥")}
                )
            except:
                pass

        # æ˜¾ç¤ºç»Ÿè®¡
        stats = client.get_statistics()
        print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")
        for key, value in stats.items():
            print(f"  {key}: {value}")

        print("\nâœ… æ•°æ®ä¿å­˜æˆåŠŸ!")
        print(f"   è®¿é—® http://localhost:7474 æŸ¥çœ‹Neo4jå›¾è°±")

        client.close()

    except Exception as e:
        logger.error(f"ä¿å­˜å¤±è´¥: {e}", exc_info=True)
        print(f"\nâŒ ä¿å­˜å¤±è´¥: {e}")
        print(f"   è¯·ç¡®ä¿Neo4jæ­£åœ¨è¿è¡Œ: docker-compose up -d")


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
    if len(sys.argv) > 1:
        file_path = sys.argv[1]
    else:
        file_path = "data/sample_novels/example.txt"
        print(f"\nğŸ’¡ ä½¿ç”¨é»˜è®¤ç¤ºä¾‹æ–‡ä»¶: {file_path}")
        print(f"   ç”¨æ³•: python scripts/full_analysis_demo.py <å°è¯´æ–‡ä»¶è·¯å¾„>\n")

    if not os.path.exists(file_path):
        print(f"\nâŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return

    try:
        # è¿è¡Œå®Œæ•´åˆ†æ
        result = demo_full_analysis(file_path)

        print("\n" + "=" * 70)
        print("âœ¨ åˆ†æå®Œæˆ!")
        print("=" * 70)
        print("\nğŸ’¡ æç¤º:")
        print("  - ä½¿ç”¨ Neo4j Browser (http://localhost:7474) å¯è§†åŒ–å›¾è°±")
        print("  - è¿è¡Œ Cypher æŸ¥è¯¢æ¢ç´¢æ•°æ®")
        print("  - æŸ¥çœ‹ README.md äº†è§£æ›´å¤šæŸ¥è¯¢ç¤ºä¾‹")

    except Exception as e:
        logger.error(f"åˆ†æå¤±è´¥: {e}", exc_info=True)
        print(f"\nâŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    main()
